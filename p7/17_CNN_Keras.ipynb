{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-fight",
   "metadata": {},
   "source": [
    "# CNN mit Keras: Hausnummern erkennen\n",
    "\n",
    "In dieser Aufgabe wollen wir einen Datensatz verwenden, der Bildausschnitte mit einzelnen Ziffern von Hausnummern enthält.\n",
    "Die Daten ähneln damit vom Prinzip her dem MNIST Datensatz.\n",
    "Da es sich um (Farb-) Fotos handelt, die zudem noch recht verrauscht sind, ist das Problem, die Ziffern zu erkennen, aber deutlich schwieriger.\n",
    "\n",
    "Wir laden zunächst die Bidler von der URL http://ufldl.stanford.edu/housenumbers herunter.\n",
    "Details zum Datensatz finden Sie in [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "url = [f\"http://ufldl.stanford.edu/housenumbers/{n}_32x32.mat\" for n in (\"train\", \"test\")]\n",
    "dfile = [f\"./{n}_32x32.mat\" for n in (\"train\", \"test\")]\n",
    "\n",
    "\n",
    "for i in range(len(url)):\n",
    "    if not os.path.isfile(dfile[i]):\n",
    "        urllib.request.urlretrieve(url[i], dfile[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-discretion",
   "metadata": {},
   "source": [
    "Die Daten liegen im `.mat`-Format vor, dass zumeist in Matlab verwendet wird.\n",
    "Wir importieren die Daten über die Funktion `scipy.io.loadmat` und extrahieren dann die Attribute und Labels jeweils aus den Test- und Trainings-Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "train_raw = loadmat('./train_32x32.mat')\n",
    "test_raw = loadmat('./test_32x32.mat')\n",
    "                   \n",
    "train_images = np.array(train_raw['X'])\n",
    "test_images = np.array(test_raw['X'])\n",
    "\n",
    "train_labels = train_raw['y']\n",
    "test_labels = test_raw['y']\n",
    "                   \n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-establishment",
   "metadata": {},
   "source": [
    "Wenn Sie sich die Dimension der Datensätze ansehen, stellen Sie fest, dass die Daten unpassend strukturiert sind.\n",
    "In den ersten Dimensionen haben wir die (RGB) Pixel der einzelnen Bilder, in der letzten Dimension die einzelnen Bilder.\n",
    "Daher sortieren wir die Dimensionen, bzw. die Axen unserer Datensätze um, sodass die erste Dimension dem Index eines Bildes entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the axes of the images\n",
    "\n",
    "train_images = np.moveaxis(train_images, -1, 0)\n",
    "test_images = np.moveaxis(test_images, -1, 0)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-reward",
   "metadata": {},
   "source": [
    "Nun können wir ein zufälliges Bild ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "# Plot a random image and its label\n",
    "\n",
    "plt.imshow(train_images[random.randint(0,len(train_images))])\n",
    "plt.show()\n",
    "\n",
    "print('Label: ', train_labels[13529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float64')\n",
    "test_images = test_images.astype('float64')\n",
    "\n",
    "train_labels = train_labels.astype('int64')\n",
    "test_labels = test_labels.astype('int64')\n",
    "\n",
    "train_images /= 255.0\n",
    "test_images /= 255.0\n",
    "\n",
    "train_labels -= 1\n",
    "test_labels -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-locator",
   "metadata": {},
   "source": [
    "Wir stellen nun ein sequenziellen Keras Model auf. Das Modell hat 2 Schichten.\n",
    "Die erste Schicht besitzt 128 Neuronen und verwendet ReLU als Aktivierungsfunktion.\n",
    "Die zweite Schicht besitzt 10 Neuronen und verwendet als Aktivierungsfunktion die Softmax-Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell definieren\n",
    "\n",
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
    "    model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-hierarchy",
   "metadata": {},
   "source": [
    "Nun wählen wir geeignete Parameter für das Modell aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modellparameter\n",
    "optimizer =  'sgd'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "#Modell erzeugen\n",
    "model.compile(optimizer,loss,metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-manhattan",
   "metadata": {},
   "source": [
    "Nun können wir das Modell trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mfile = \"./model.h5\"\n",
    "\n",
    "if not os.path.isfile(mfile):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer,loss,metrics)\n",
    "else:\n",
    "    print(\"Load Model from file\", mfile)\n",
    "    model = tf.keras.models.load_model(mfile)\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=5)\n",
    "model.save(mfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24539ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainiertes Modell auswerten\n",
    "test_loss, test_acc = model.evaluate (test_images, test_labels)\n",
    "print('Classification Accuracy (Test):', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb50392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Classification Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoche')\n",
    "plt.legend(['Test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Kostenfunktion')\n",
    "plt.ylabel('Fehler')\n",
    "plt.xlabel('Epoche')\n",
    "plt.legend(['Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9df70",
   "metadata": {},
   "source": [
    "**Aufgabe:** Erstellen Sie ein Faltungsnetz (CNN) mit folgenden Schichten über die *Keras Sequential API*:\n",
    "\n",
    "1. Die erste Schicht soll ein `Conv2D`-Layer sein. Sie benötigen keinen zusätzlichen `Flatten`-Layer. Verwenden Sie in der ersten Schicht einfach den Parameter `input_shape` und setzen Sie ihn auf das 3-Tupel `(32, 32, 3)` (32x32 Pixel im RGB Format). Die `Conv2D`-Schicht soll 16 Filtermasken einer Größe von $3\\times{}3$ Pixeln verwenden. Als Aktivierungsfunktion verwenden Sie `relu`.\n",
    "2. Die zweite Schicht ist ein Pooling-Layer. Fassen Sie immer $2\\times{}2$ Pixel mit Max-Pooling (`MaxPooling2D`) zusammen.\n",
    "3. Um Overfitting zu vermeiden, führen wir ein Dropout-Layer ein. Verwenden die eine Dropout-Rate von 30%.\n",
    "4. Fügen Sie je eine weitere `Conv2D`, `MaxPooling2D` und `Dropout` Schicht ein. Die Parameter sollen wie bei 1.-3. gewählt werden, mit der Ausnahme, dass die `Conv2D`-Schicht nun doppelt so viele (also 32) Filtermasken verwenden soll.\n",
    "5. Transformieren Sie die 2D-Daten in 1D- Daten mit einem `Flatten`-Layer. `Flatten` benötigt keine Parameter.\n",
    "6. Fügen Sie dem Modell eine voll-vermaschte Schicht (`Dense`) mit 256 Neuronen hinzu. Als Aktivierungsfunktion soll hier acuh `relu` verwendet werden.\n",
    "7. Fügen Sie ein Dropout Schicht mit 30% Dropout rate ein\n",
    "8. Fügen Sie dem Modell einen Eine Ausgabeschicht mit 10 Neuronen hinzu (`Dense`). Die Aktivierungsfunktion hier sollte `softmax` sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2e447",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-903b5e0666c97127",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Modell definieren\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d4f1a",
   "metadata": {},
   "source": [
    "Nun trainieren wir das Modell und schreiben die Trainierten Parameter erneut in eine Datei.\n",
    "\n",
    "(*Hinweis:* Achten Sie darauf, die Datei zu löschen, falls Sie ein neues Modell erzeugt haben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfile = \"./model_cnn.h5\"\n",
    "\n",
    "if not os.path.isfile(mfile):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer,loss,metrics)\n",
    "else:\n",
    "    print(\"Load Model from file\", mfile)\n",
    "    model = tf.keras.models.load_model(mfile)\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=5)\n",
    "model.save(mfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea60224d",
   "metadata": {},
   "source": [
    "Wir können nun das trainierte Modell bewerten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainiertes Modell auswerten\n",
    "test_loss, test_acc = model.evaluate (test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-cathedral",
   "metadata": {},
   "source": [
    "### Referenzen\n",
    "\n",
    "[1] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng. *\"Reading Digits in Natural Images with Unsupervised Feature Learning\"*,  NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
